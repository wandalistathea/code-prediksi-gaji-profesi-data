{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Jobstreet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(\"chromedriver.exe\")\n",
    "browser.get(\"https://myjobstreet.jobstreet.co.id/home/login.php?site=id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = browser.find_element(By.ID, \"login_id\")\n",
    "username.send_keys(\"masukkan email\")\n",
    "\n",
    "password = browser.find_element(By.ID, \"password\")\n",
    "password.send_keys(\"masukkan password\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "login_button = browser.find_element(By.XPATH, \"//button[@name = 'btn_login']\")\n",
    "login_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap Multiple Page -> Untuk Search Term List (Beberapa Kata Kunci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION UNTUK MENCARI DARI SEARCH TERM LIST\n",
    "\n",
    "def job_jobstreet_list(search_term_list, search_loc):\n",
    "    \n",
    "    # Data frame awal\n",
    "    df = pd.DataFrame(columns = [\"job_name\", \"company\", \"lokasi\", \n",
    "                                 \"Tingkat Pekerjaan\", \"Kualifikasi\", \"Pengalaman Kerja\", \"Jenis Pekerjaan\", \"Spesialisasi Pekerjaan\", \n",
    "                                 \"No. Registrasi\", \"Ukuran Perusahaan\", \"Waktu Proses Lamaran\", \"Industri\", \"Tunjangan dan Lain-lain\", \"Lokasi\", \n",
    "                                 \"gaji\"])\n",
    "    \n",
    "    # For looping untuk \"search term list\"\n",
    "    for search_term in search_term_list:\n",
    "    \n",
    "        # Isian untuk cari berdasarkan pekerjaan dan lokasi\n",
    "        search_term_isi = browser.find_element(By.ID, \"searchKeywordsField\")\n",
    "        search_term_isi.send_keys(search_term)\n",
    "\n",
    "        search_loc_isi = browser.find_element(By.ID, \"locationAutoSuggest\")\n",
    "        search_loc_isi.send_keys(search_loc)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        search_button = browser.find_element(By.XPATH, \"//button[@type = 'submit']\")\n",
    "        search_button.click()\n",
    "\n",
    "        browser.implicitly_wait(10)\n",
    "\n",
    "        #-------------------------------------------------------------------------------\n",
    "        # UNTUK PAGE = 1 (langsung scraping saja karena tidak perlu klik page button-nya)\n",
    "        # Scroll sampai bawah dan kembalikan ke atas\n",
    "        element = browser.find_element(By.TAG_NAME, \"body\")\n",
    "        for i in range(1, 15):\n",
    "            browser.execute_script(\"window.scrollBy(0, 560)\", \"\")\n",
    "            time.sleep(0.5)\n",
    "        time.sleep(1)\n",
    "        element.send_keys(Keys.HOME)\n",
    "\n",
    "        # Melihat banyaknya pages\n",
    "        pagination = browser.find_elements(By.XPATH, \"//select[@id = 'pagination']/option\")\n",
    "        max_pages = int(pagination[-1].text)\n",
    "        pages = [x for x in range(2, max_pages+1)]\n",
    "\n",
    "        # List nama-nama lowongan\n",
    "        job_all = browser.find_elements(By.XPATH, \"//div[@class = 'sx2jih0 zcydq8bm']/h1/a\")\n",
    "        list_job_oke = [i for i in job_all if search_term in i.text.lower()]\n",
    "\n",
    "        for job in list_job_oke:\n",
    "            job.click()\n",
    "            time.sleep(1)\n",
    "\n",
    "            # 1. BAGIAN AWAL\n",
    "            list_hal_awal1 = browser.find_elements(By.XPATH, \"//div[@class = 'sx2jih0 zcydq86m']\")\n",
    "            list_hal_awal2 = browser.find_elements(By.XPATH, \"//div[@class = 'sx2jih0 zcydq86a']\")\n",
    "\n",
    "            list_hapus1 = []\n",
    "            for i in range(0, len(list_hal_awal1)):\n",
    "                if list_hal_awal1[i].text == \"\":\n",
    "                    list_hapus1.append(i)\n",
    "            del list_hal_awal1[list_hapus1[0]:list_hapus1[-1]+1]\n",
    "\n",
    "            if len(list_hal_awal1) == 2:\n",
    "                job_name = list_hal_awal1[0].text\n",
    "                company = list_hal_awal1[1].text\n",
    "            elif len(list_hal_awal1) == 3:\n",
    "                job_name = list_hal_awal1[0].text + list_hal_awal1[1].text\n",
    "                company = list_hal_awal1[2].text\n",
    "\n",
    "            if len(list_hal_awal2) == 2:\n",
    "                lokasi = list_hal_awal2[0].text\n",
    "                gaji = np.nan\n",
    "            elif len(list_hal_awal2) == 3:\n",
    "                lokasi = list_hal_awal2[0].text\n",
    "                gaji = list_hal_awal2[1].text\n",
    "\n",
    "            # 2. BAGIAN INFORMASI TAMBAHAN\n",
    "            info = browser.find_elements(By.XPATH, \"//div[@class = 'sx2jih0 zcydq86i']/span\")\n",
    "            list_info = [i.text for i in info]\n",
    "\n",
    "            del list_info[-1] # Index terakhir itu kosong (\"\")\n",
    "            nama_kolom = list_info[0:len(list_info):2]\n",
    "\n",
    "            del list_info[0:len(list_info):2] # Hapus kolomnya\n",
    "            isi_kolom = list_info # Ini list_info yang sudah kehapus nama kolomnya\n",
    "            dict_info = dict(zip(nama_kolom, isi_kolom))\n",
    "\n",
    "            dict1 = {\"job_name\": job_name, \"company\": company, \"lokasi\": lokasi}\n",
    "            dict1.update(dict_info)\n",
    "            dict1.update({\"gaji\": gaji})\n",
    "\n",
    "            df = df.append(dict1, ignore_index = True) \n",
    "\n",
    "        # Untuk ke page 2 -> tidak ada tombol \"Sebelumnya\"\n",
    "        klik_next = browser.find_element(By.XPATH, \"//a/span[@class = 'sx2jih0 zcydq84u _18qlyvc0 _18qlyvc1x _18qlyvc1 _1d0g9qk4 _18qlyvc5']\")\n",
    "        klik_next.click()\n",
    "        #time.sleep(2)\n",
    "        browser.implicitly_wait(10)\n",
    "\n",
    "        #-------------------------------------------------------------------------------\n",
    "        # UNTUK PAGE > 1 (perlu klik page button-nya)\n",
    "\n",
    "        # For loop untuk page\n",
    "        for page in pages:  \n",
    "\n",
    "            # Scroll sampai bawah dan kembalikan ke atas\n",
    "            element = browser.find_element(By.TAG_NAME, \"body\")\n",
    "            for i in range(1, 15):\n",
    "                browser.execute_script(\"window.scrollBy(0, 560)\", \"\")\n",
    "                time.sleep(0.5)\n",
    "            time.sleep(1)\n",
    "            element.send_keys(Keys.HOME)\n",
    "\n",
    "            # List nama-nama lowongan\n",
    "            job_all = browser.find_elements(By.XPATH, \"//div[@class = 'sx2jih0 zcydq8bm']/h1/a\")\n",
    "            list_job_oke = [i for i in job_all if search_term in i.text.lower()]\n",
    "\n",
    "            for job in list_job_oke:\n",
    "                job.click()\n",
    "                time.sleep(1)\n",
    "\n",
    "                # 1. BAGIAN AWAL\n",
    "                list_hal_awal1 = browser.find_elements(By.XPATH, \"//div[@class = 'sx2jih0 zcydq86m']\")\n",
    "                list_hal_awal2 = browser.find_elements(By.XPATH, \"//div[@class = 'sx2jih0 zcydq86a']\")\n",
    "\n",
    "                list_hapus1 = []\n",
    "                for i in range(0, len(list_hal_awal1)):\n",
    "                    if list_hal_awal1[i].text == \"\":\n",
    "                        list_hapus1.append(i)\n",
    "                del list_hal_awal1[list_hapus1[0]:list_hapus1[-1]+1]\n",
    "\n",
    "                if len(list_hal_awal1) == 2:\n",
    "                    job_name = list_hal_awal1[0].text\n",
    "                    company = list_hal_awal1[1].text\n",
    "                elif len(list_hal_awal1) == 3:\n",
    "                    job_name = list_hal_awal1[0].text + list_hal_awal1[1].text\n",
    "                    company = list_hal_awal1[2].text\n",
    "\n",
    "                if len(list_hal_awal2) == 2:\n",
    "                    lokasi = list_hal_awal2[0].text\n",
    "                    gaji = np.nan\n",
    "                elif len(list_hal_awal2) == 3:\n",
    "                    lokasi = list_hal_awal2[0].text\n",
    "                    gaji = list_hal_awal2[1].text\n",
    "\n",
    "                # 2. BAGIAN INFORMASI TAMBAHAN\n",
    "                info = browser.find_elements(By.XPATH, \"//div[@class = 'sx2jih0 zcydq86i']/span\")\n",
    "                list_info = [i.text for i in info]\n",
    "\n",
    "                del list_info[-1] # Index terakhir itu kosong (\"\")\n",
    "                nama_kolom = list_info[0:len(list_info):2]\n",
    "\n",
    "                del list_info[0:len(list_info):2] # Hapus kolomnya\n",
    "                isi_kolom = list_info # Ini list_info yang sudah kehapus nama kolomnya\n",
    "                dict_info = dict(zip(nama_kolom, isi_kolom))\n",
    "\n",
    "                dict1 = {\"job_name\": job_name, \"company\": company, \"lokasi\": lokasi}\n",
    "                dict1.update(dict_info)\n",
    "                dict1.update({\"gaji\": gaji})\n",
    "\n",
    "                df = df.append(dict1, ignore_index = True)\n",
    "\n",
    "            # Untuk ke page >2 -> ada tombol \"Sebelumnya\"\n",
    "            klik_next = browser.find_elements(By.XPATH, \"//a/span[@class = 'sx2jih0 zcydq84u _18qlyvc0 _18qlyvc1x _18qlyvc1 _1d0g9qk4 _18qlyvc5']\")\n",
    "\n",
    "            if len(klik_next) == 2:\n",
    "                klik_next[-1].click()\n",
    "                #time.sleep(2)\n",
    "                browser.implicitly_wait(10)\n",
    "                \n",
    "        browser.implicitly_wait(5)\n",
    "        search_term_isi.send_keys(Keys.CONTROL + \"a\")\n",
    "        search_term_isi.send_keys(Keys.DELETE)\n",
    "        search_loc_isi.send_keys(Keys.CONTROL + \"a\")\n",
    "        search_loc_isi.send_keys(Keys.DELETE)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "search_term_list = [\"data scientist\", \"data analyst\", \"data engineer\"]\n",
    "hasil = job_jobstreet_list(search_term_list, \"indonesia\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"Durasi Scraping: {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "hasil.to_csv(\"Scraping Profesi Data (Jobstreet).csv\", index = False)\n",
    "\n",
    "# Data diambil tanggal 6 Des 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Membaca data yang sudah disimpan\n",
    "df = pd.read_csv(\"Scraping Profesi Data (Jobstreet).csv\")\n",
    "df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
