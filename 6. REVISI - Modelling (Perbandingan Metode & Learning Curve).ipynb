{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling (Perbandingan Metode & Learning Curve SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_oke = pd.read_csv(\"Data Gabungan Hasil Preprocessing Tahap 2 (3 Profesi).csv\")\n",
    "data_oke.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalau pakai k-fold cross validation berarti langsung pakai semua data\n",
    "X = data_oke.drop(\"median_gaji\", axis = 1)\n",
    "y = data_oke[\"median_gaji\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Pakai Data Asli (Tanpa Resampling) -> Untuk Perbandingan 3 Metode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree = DecisionTreeRegressor(random_state = 0)\n",
    "\n",
    "# PAKAI CROSS VAL\n",
    "from sklearn.model_selection import cross_val_score\n",
    "r2_tree = cross_val_score(estimator = tree, X = X, y = y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2_tree.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tree_x = DecisionTreeRegressor(random_state = 0)\n",
    "param_grid = {\"max_depth\": list(range(11)), \n",
    "              \"criterion\": [\"mse\", \"friedman_mse\", \"mae\"], \n",
    "              \"max_features\": [\"auto\", \"sqrt\", \"log2\"], \n",
    "              \"min_samples_split\": list(range(6))}\n",
    "\n",
    "grid_search_x = GridSearchCV(tree_x, param_grid, n_jobs = 2, verbose = 1, cv = 5)\n",
    "\n",
    "grid_search_x.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_x.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ini nilai score test (R2)-nya\n",
    "grid_search_x.best_score_ # Mean cross-validated score of the best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# COBA BUAT MODEL BERDASARKAN \"best_params_\"\n",
    "tree_x1 = DecisionTreeRegressor(random_state = 0, \n",
    "                                criterion = 'mae',\n",
    "                                max_depth = 2,\n",
    "                                max_features = 'sqrt',\n",
    "                                min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PAKAI CROSS VAL\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "\n",
    "r2_tree_x1 = cross_val_score(estimator = tree_x1, X = X, y = y, cv = 5, scoring  ='r2')\n",
    "nrmse_tree_x1 = cross_val_score(estimator = tree_x1, X = X, y = y, cv = 5, scoring  ='neg_root_mean_squared_error')\n",
    "nmape_tree_x1 = cross_val_score(estimator = tree_x1, X = X, y = y, cv = 5, scoring  ='neg_mean_absolute_percentage_error')\n",
    "\n",
    "r2_tree_x1 = mean(r2_tree_x1)\n",
    "rmse_tree_x1 = mean(absolute(nrmse_tree_x1))\n",
    "mape_tree_x1 = mean(absolute(nmape_tree_x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 TREE:\", r2_tree_x1)\n",
    "print(\"RMSE TREE:\", rmse_tree_x1)\n",
    "print(\"MAPE TREE:\", mape_tree_x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Menampilkan Grafik Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = grid_search_x.best_estimator_ # model ini sama dengan tree_x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (25, 20))\n",
    "_ = tree.plot_tree(tree_model, feature_names = X.columns, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"grafik decision tree (bagian perbandingan metode).png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest = RandomForestRegressor(random_state = 0)\n",
    "\n",
    "# PAKAI CROSS VAL\n",
    "from sklearn.model_selection import cross_val_score\n",
    "r2_rf = cross_val_score(estimator = random_forest, X = X, y = y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_rf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "random_forest_x = RandomForestRegressor(random_state = 0)\n",
    "param_grid = {\"n_estimators\": list(range(100, 131)),\n",
    "              \"criterion\": [\"squared_error\", \"absolute_error\"],\n",
    "              \"max_depth\": list(range(11)), \n",
    "              \"max_features\": [\"auto\", \"sqrt\", \"log2\"], \n",
    "              \"min_samples_split\": list(range(2, 16))}\n",
    "\n",
    "# grid_search_x1 = GridSearchCV(random_forest_x, param_grid, n_jobs = 2, verbose = 1, cv = 5)\n",
    "# grid_search_x1.fit(X, y)\n",
    "\n",
    "random_search_x = RandomizedSearchCV(random_forest_x, param_grid, cv = 5, n_jobs = 2, verbose = 1, \n",
    "                                     n_iter = 1000, random_state = 0)\n",
    "# Harusnya kandidatnya ada banyak, tapi n_iter = 1000 jadi cuma pilih 1000 saja\n",
    "random_search_x.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_x.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_x.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# COBA BUAT MODEL BERDASARKAN \"best_params_\"\n",
    "random_forest_x1 = RandomForestRegressor(random_state = 0, \n",
    "                                         n_estimators = 122,\n",
    "                                         min_samples_split = 13,\n",
    "                                         max_features = 'auto',\n",
    "                                         max_depth = 2,\n",
    "                                         criterion = 'squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PAKAI CROSS VAL\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "\n",
    "r2_rf_x1 = cross_val_score(estimator = random_forest_x1, X = X, y = y, cv = 5, scoring  ='r2')\n",
    "nrmse_rf_x1 = cross_val_score(estimator = random_forest_x1, X = X, y = y, cv = 5, scoring  ='neg_root_mean_squared_error')\n",
    "nmape_rf_x1 = cross_val_score(estimator = random_forest_x1, X = X, y = y, cv = 5, scoring  ='neg_mean_absolute_percentage_error')\n",
    "\n",
    "r2_rf_x1 = mean(r2_rf_x1)\n",
    "rmse_rf_x1 = mean(absolute(nrmse_rf_x1))\n",
    "mape_rf_x1 = mean(absolute(nmape_rf_x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 RANDOM FOREST:\", r2_rf_x1)\n",
    "print(\"RMSE RANDOM FOREST:\", rmse_rf_x1)\n",
    "print(\"MAPE RANDOM FOREST:\", mape_rf_x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Menampilkan Grafik Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = random_search_x.best_estimator_ # model ini sama dengan random_forest_x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.estimators_ # masing-masing DT-nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rf_model.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (25, 20))\n",
    "_ = tree.plot_tree(rf_model.estimators_[1], feature_names = X.columns, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"grafik random forest (bagian perbandingan metode)_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "# PAKAI CROSS VAL\n",
    "from sklearn.model_selection import cross_val_score\n",
    "r2_svr = cross_val_score(estimator = svr, X = X, y = y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_svr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "svr_x = SVR()\n",
    "param_grid = {\"gamma\": np.logspace(-2, 2, 20), \n",
    "              \"C\": np.logspace(-2, 2, 20)}\n",
    "\n",
    "grid_search_x2 = GridSearchCV(svr_x, param_grid, n_jobs = 2, verbose = 1, cv = 5)\n",
    "grid_search_x2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search_x2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_x2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# COBA BUAT MODEL BERDASARKAN \"best_params_\"\n",
    "svr_x1 = SVR(C = 100.0, \n",
    "             gamma = 0.11288378916846889)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PAKAI CROSS VAL\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "\n",
    "r2_svr_x1 = cross_val_score(estimator = svr_x1, X = X, y = y, cv = 5, scoring  ='r2')\n",
    "nrmse_svr_x1 = cross_val_score(estimator = svr_x1, X = X, y = y, cv = 5, scoring  ='neg_root_mean_squared_error')\n",
    "nmape_svr_x1 = cross_val_score(estimator = svr_x1, X = X, y = y, cv = 5, scoring  ='neg_mean_absolute_percentage_error')\n",
    "\n",
    "r2_svr_x1 = mean(r2_svr_x1)\n",
    "rmse_svr_x1 = mean(absolute(nrmse_svr_x1))\n",
    "mape_svr_x1 = mean(absolute(nmape_svr_x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"R2 SVR:\", r2_svr_x1)\n",
    "print(\"RMSE SVR:\", rmse_svr_x1)\n",
    "print(\"MAPE SVR:\", mape_svr_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = grid_search_x2.best_estimator_ # model ini sama dengan svr_x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"intercept:\", svr_model.intercept_)\n",
    "print(\"dual_coef:\", svr_model.dual_coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. SMOTE (Learning Curve) -> Bandingkannya dengan Model Decision Tree Hasil Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data Gabungan dari Linkedin dan Jobstreet (3 Profesi).csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(data, oversample = range(37, 101)):\n",
    "    r2_tree = []\n",
    "    rmse_tree = []\n",
    "    mape_tree = []\n",
    "    \n",
    "    # Hapus kolom yang tidak digunakan\n",
    "    data.drop([\"company\", \"gaji\", \"sumber\"], axis = 1, inplace = True)\n",
    "\n",
    "    # Hapus data/row yang \"median_gaji\"-nya berupa missing value\n",
    "    data.dropna(subset = [\"median_gaji\"], inplace = True)\n",
    "\n",
    "    data.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    # Hapus \"jenis_job\" karena korelasi <=0.25\n",
    "    data.drop([\"jenis_job\"], axis = 1, inplace = True)\n",
    "\n",
    "    #--------------- Handling Missing Value\n",
    "    # 1. Menangani Missing Value di \"ukuran_company\"\n",
    "    # Coba berdasarkan variabel -> \"job_name\"\n",
    "    import statistics\n",
    "    mode_ukuran_company1 = data[data[\"ukuran_company\"].notna()].groupby([\"job_name\"])[\"ukuran_company\"].apply(statistics.mode)\n",
    "\n",
    "    dict_group1a = {}\n",
    "    for indeks in mode_ukuran_company1.index:    \n",
    "        group1a = {indeks: mode_ukuran_company1[indeks]}\n",
    "        dict_group1a.update(group1a)\n",
    "\n",
    "    missing_ukuran_company1 = data[pd.isna(data[\"ukuran_company\"])]\n",
    "    for i in missing_ukuran_company1.index:\n",
    "        for j in dict_group1a.keys():\n",
    "            data_asli = (data[\"job_name\"][i])\n",
    "            if data_asli == j:\n",
    "                data[\"ukuran_company\"][i] = dict_group1a[j]\n",
    "\n",
    "    # 2. Menangani Missing Value di \"industri\"\n",
    "    # Coba berdasarkan variabel -> \"job_name\"\n",
    "    mode_industri1 = data[data[\"industri\"].notna()].groupby([\"job_name\"])[\"industri\"].apply(statistics.mode) # Pakainya modus karena data kategorik\n",
    "    mode_industri1 \n",
    "    # Sama semua sehingga ada yang akan diambil nilai modus kedua\n",
    "    # \"data analyst\" pakai yang industri \"konsultasi\"\n",
    "    \n",
    "    # Coba impute menggunakan modus yang lain\n",
    "    impute_industri = {\"data analyst\": \"konsultasi\", \n",
    "                       \"data engineer\": \"teknologi informasi dan komunikasi\", \n",
    "                       \"data scientist\": \"teknologi informasi dan komunikasi\"}\n",
    "\n",
    "    missing_industri1 = data[pd.isna(data[\"industri\"])]\n",
    "\n",
    "    for i in missing_industri1.index:\n",
    "        for j in impute_industri.keys():\n",
    "            data_asli = (data[\"job_name\"][i])\n",
    "\n",
    "            if data_asli == j:\n",
    "                data[\"industri\"][i] = impute_industri[j]\n",
    "\n",
    "    # 3. Menangani Missing Value di \"lama_pengalaman\"\n",
    "    # Cek distribusi dari datanya terlebih dahulu\n",
    "    filtered_lama_pengalaman = data[\"lama_pengalaman\"][~np.isnan(data[\"lama_pengalaman\"])]\n",
    "    plt.boxplot(filtered_lama_pengalaman, meanline = True, showmeans = True)\n",
    "    plt.title(\"Boxplot Lama Pengalaman\")\n",
    "    plt.ylabel(\"Lama Pengalaman (Tahun)\")\n",
    "    #plt.savefig(\"1. Boxplot Lama Pengalaman (Untuk Handling Missing Value) REVISI.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    import seaborn as sns\n",
    "    sns.distplot(filtered_lama_pengalaman, hist = False, kde = True, axlabel = \"Lama Pengalaman (Tahun)\")\n",
    "    #plt.savefig(\"1. Distplot Lama Pengalaman (Untuk Handling Missing Value) REVISI.png\")\n",
    "    plt.show()\n",
    "    # Distribusi cenderung Normal sehingga penggantinya akan menggunakan nilai mean\n",
    "    \n",
    "    # Coba berdasarkan variabel -> \"job_name\"\n",
    "    mean_lama_pengalaman1 = data[data[\"lama_pengalaman\"].notna()].groupby([\"job_name\"])[\"lama_pengalaman\"].mean()\n",
    "\n",
    "    dict_group4a = {}\n",
    "    for indeks in mean_lama_pengalaman1.index:      \n",
    "        group4a = {indeks: round(mean_lama_pengalaman1[indeks], 1)}\n",
    "        dict_group4a.update(group4a)\n",
    "\n",
    "    missing_lama_pengalaman1 = data[pd.isna(data[\"lama_pengalaman\"])]\n",
    "    for i in missing_lama_pengalaman1.index:\n",
    "        for j in dict_group4a.keys():\n",
    "            data_asli = (data[\"job_name\"][i])\n",
    "            if data_asli == j:\n",
    "                data[\"lama_pengalaman\"][i] = dict_group4a[j]\n",
    "\n",
    "    #--------------- Handling Categorical Data\n",
    "    data_oke = data.copy()\n",
    "\n",
    "    # NOMINAL -> \"job_name\", \"lokasi\", \"industri\" (pakai get_dummies)\n",
    "    # ORDINAL -> \"tingkat_job\", \"ukuran_company\" (pakai OrdinalEncoder)\n",
    "\n",
    "    # 1. NOMINAL\n",
    "    # \"lokasi\", \"industri\"\n",
    "    nominal_cols = data_oke[[\"lokasi\", \"industri\"]]\n",
    "    encoded_nominal = pd.get_dummies(data = nominal_cols)\n",
    "    # Gabungkan ke data asli\n",
    "    data_oke = pd.concat(objs = [encoded_nominal, data_oke], axis = 1)\n",
    "    data_oke.drop(nominal_cols, axis = 1, inplace = True)\n",
    "\n",
    "    # 2. ORDINAL\n",
    "    import category_encoders as ce\n",
    "\n",
    "    # 1) \"tingkat_job\"\n",
    "    encoder_tingkat_job = ce.OrdinalEncoder(cols = [\"tingkat_job\"], return_df = True, \n",
    "                                            mapping = [{\"col\": \"tingkat_job\", \n",
    "                                                        \"mapping\": {\"magang\": 0, \"tingkat pemula\": 1, \"asosiasi\": 2, \n",
    "                                                                    \"senior tingkat menengah\": 3, \"direktur\": 4, \"eksekutif\": 5}}])\n",
    "    data_oke[\"tingkat_job\"] = encoder_tingkat_job.fit_transform(data_oke[\"tingkat_job\"])\n",
    "\n",
    "    # 2) \"ukuran_company\"\n",
    "    encoder_ukuran_company = ce.OrdinalEncoder(cols = [\"ukuran_company\"], return_df = True, \n",
    "                                               mapping = [{\"col\": \"ukuran_company\", \n",
    "                                                           \"mapping\": {\"1-50 pekerja\": 0, \"51-200 pekerja\": 1, \"201-500 pekerja\": 2,\n",
    "                                                                       \"501-1.000 pekerja\": 3, \"1.001-5.000 pekerja\": 4, \">5.000 pekerja\": 5}}])\n",
    "    data_oke[\"ukuran_company\"] = encoder_ukuran_company.fit_transform(data_oke[\"ukuran_company\"])\n",
    "\n",
    "    for n in oversample:\n",
    "        \n",
    "        #--------------- SMOTE Pakai Semua Data\n",
    "        # Karena mau pakai SMOTE, yang jadi y itu nama profesi data dulu\n",
    "        X = data_oke.drop(\"job_name\", axis = 1)\n",
    "        y = data_oke[\"job_name\"]\n",
    "\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        strategy = {\"data analyst\": n, \"data engineer\": n, \"data scientist\": n}\n",
    "        oversample = SMOTE(random_state = 0, sampling_strategy = strategy)\n",
    "        X_smote, y_smote = oversample.fit_resample(X, y)\n",
    "\n",
    "        data_smote = pd.concat([y_smote, X_smote], axis = 1)\n",
    "\n",
    "        # NOMINAL\n",
    "        # \"job_name\"\n",
    "        nominal_cols = data_smote[[\"job_name\"]]\n",
    "        encoded_nominal = pd.get_dummies(data = nominal_cols)\n",
    "        # Gabungkan ke data asli\n",
    "        data_smote = pd.concat(objs = [encoded_nominal, data_smote], axis = 1)\n",
    "        data_smote.drop(nominal_cols, axis = 1, inplace = True)\n",
    "\n",
    "        #--------------- Target Engineering\n",
    "        from scipy import stats\n",
    "\n",
    "        # Transformasi Box-Cox\n",
    "        transformed_data, best_lambda = stats.boxcox(data_smote[\"median_gaji\"]) \n",
    "        nilai_lambda = best_lambda\n",
    "\n",
    "        # Transformasikan\n",
    "        data_smote[\"median_gaji\"] = transformed_data\n",
    "\n",
    "        #--------------- K-Fold Cross Validation\n",
    "        # Kalau pakai k-fold cross validation berarti langsung pakai semua data\n",
    "        X = data_smote.drop(\"median_gaji\", axis = 1)\n",
    "        y = data_smote[\"median_gaji\"]\n",
    "\n",
    "        #--------------- Modelling Decision Tree\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "        # COBA BUAT MODEL BERDASARKAN \"best_params_\"\n",
    "        tree_x1 = DecisionTreeRegressor(random_state = 0, \n",
    "                                        criterion = 'mae',\n",
    "                                        max_depth = 2,\n",
    "                                        max_features = 'sqrt',\n",
    "                                        min_samples_split = 2)\n",
    "\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        from numpy import mean\n",
    "        from numpy import absolute\n",
    "\n",
    "        r2_tree_x1 = cross_val_score(estimator = tree_x1, X = X, y = y, cv = 5, scoring  ='r2')\n",
    "        nrmse_tree_x1 = cross_val_score(estimator = tree_x1, X = X, y = y, cv = 5, scoring  ='neg_root_mean_squared_error')\n",
    "        nmape_tree_x1 = cross_val_score(estimator = tree_x1, X = X, y = y, cv = 5, scoring  ='neg_mean_absolute_percentage_error')\n",
    "\n",
    "        r2_tree_x1 = mean(r2_tree_x1)\n",
    "        rmse_tree_x1 = mean(absolute(nrmse_tree_x1))\n",
    "        mape_tree_x1 = mean(absolute(nmape_tree_x1))\n",
    "\n",
    "        r2_tree.append(r2_tree_x1)\n",
    "        rmse_tree.append(rmse_tree_x1)\n",
    "        mape_tree.append(mape_tree_x1)\n",
    "\n",
    "        df = pd.DataFrame(list(zip(r2_tree, rmse_tree,  mape_tree)), columns = [\"r2_tree\", \"rmse_tree\", \"mape_tree\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "score_lc = learning_curve(data, oversample = range(37, 101))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"Durasi Learning Curve: {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grafik R2\n",
    "plt.plot(range(37, 101), score_lc[0:64][\"r2_tree\"], linewidth = 4)\n",
    "plt.title(\"SMOTE Learning Curve (R2)\", fontsize = 16)\n",
    "plt.gca().set_xlabel(\"# of Points per Class\", fontsize = 14)\n",
    "plt.gca().set_ylabel(\"Cross Val R2\", fontsize = 14)\n",
    "sns.despine()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grafik RMSE\n",
    "plt.plot(range(37, 101), score_lc[0:64][\"rmse_tree\"], linewidth = 4)\n",
    "plt.title(\"SMOTE Learning Curve (RMSE)\", fontsize = 16)\n",
    "plt.gca().set_xlabel(\"# of Points per Class\", fontsize = 14)\n",
    "plt.gca().set_ylabel(\"Cross Val RMSE\", fontsize = 14)\n",
    "sns.despine()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grafik MAPE\n",
    "plt.plot(range(37, 101), score_lc[0:64][\"mape_tree\"], linewidth = 4)\n",
    "plt.title(\"SMOTE Learning Curve (MAPE)\", fontsize = 16)\n",
    "plt.gca().set_xlabel(\"# of Points per Class\", fontsize = 14)\n",
    "plt.gca().set_ylabel(\"Cross Val MAPE\", fontsize = 14)\n",
    "sns.despine()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InsyaAlloh SMOTE-nya pakai n = 87"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
